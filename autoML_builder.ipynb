{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LetMFzjvm4d",
        "outputId": "d1f7b9bf-c7cb-4cf1-b8b5-61719468cc1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting h2o\n",
            "  Downloading h2o-3.46.0.4.tar.gz (265.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.3/265.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.32.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.39.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2024.7.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.46.0.4-py2.py3-none-any.whl size=265375569 sha256=e6554363ec7a518935a1573d5d3693ef0889af266f0aa6f62ebe59e2c72951d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/a6/47/8bfeb1026fd65cb8630beb74d8e3bec844f572cf4f336fdd56\n",
            "Successfully built h2o\n",
            "Installing collected packages: pyngrok, h11, uvicorn, starlette, h2o, fastapi\n",
            "Successfully installed fastapi-0.112.1 h11-0.14.0 h2o-3.46.0.4 pyngrok-7.2.0 starlette-0.38.2 uvicorn-0.30.6\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn h2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnJEmNX_vwO5",
        "outputId": "f5aeac71-66cc-42d2-90da-9d21848e6a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 'YOUR_NGROK_AUTHTOKEN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL6A5xM_zgNK",
        "outputId": "b1e33356-1dc9-4266-e8ae-bea3e45ac16a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import asyncio\n",
        "import sched\n",
        "import time\n",
        "from fastapi import FastAPI, UploadFile, File, Form\n",
        "from fastapi.responses import JSONResponse\n",
        "import pandas as pd\n",
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "from io import StringIO\n",
        "import uuid\n",
        "\n",
        "app = FastAPI()\n",
        "h2o.init()\n",
        "\n",
        "# in-memory storage for tasks (the queue that contains tasks and their ids)\n",
        "tasks = {}\n",
        "scheduler = sched.scheduler(time.time, time.sleep)\n",
        "\n",
        "# the predifined statuses possible (4)\n",
        "class TaskStatus:\n",
        "    WAITING = \"waiting\"\n",
        "    IN_PROGRESS = \"in_progress\"\n",
        "    DONE = \"done\"\n",
        "    ERROR = \"error\"\n",
        "\n",
        "# the function that limits rows in the dataset in order to minimize training time\n",
        "def limit_rows(df, max_rows=500):\n",
        "    num_rows, num_cols = df.shape\n",
        "    df_non_null = df.dropna()\n",
        "    # if the rows num exceeds the threshold, we extract randomly 500 rows from the dataset\n",
        "    if len(df_non_null) > max_rows:\n",
        "        df_non_null = df_non_null.sample(n=max_rows, random_state=42)\n",
        "    return df_non_null\n",
        "\n",
        "def train_model_task(task_id, file_content):\n",
        "    try:\n",
        "        # change the task's status to in progress and put the dataset in a h2oframe\n",
        "        tasks[task_id]['status'] = TaskStatus.IN_PROGRESS\n",
        "        csv_data = StringIO(file_content.decode('utf-8'))\n",
        "        df = pd.read_csv(csv_data)\n",
        "        df = limit_rows(df)\n",
        "        h2o_df = h2o.H2OFrame(df)\n",
        "        x = h2o_df.columns\n",
        "        y = x[-1]\n",
        "        x.remove(y)\n",
        "        # define the problem type (classification if target variable is not numeric or if numeric and unique values are less than 10, else it's regression)\n",
        "        prob_type = \"regression\"\n",
        "        target_unique_values = h2o_df[y].unique().nrow\n",
        "        if (h2o_df[y].isnumeric()[0] and target_unique_values < 10) or not h2o_df[y].isnumeric()[0]:\n",
        "            prob_type = \"classification\"\n",
        "            h2o_df[y] = h2o_df[y].asfactor()\n",
        "        # train h2o model with three algos and a max of 10 models\n",
        "        include_algos = [\"GLM\", \"GBM\", \"XGBoost\"]\n",
        "        aml = H2OAutoML(max_models=10, seed=1, include_algos=include_algos)\n",
        "        aml.train(x=x, y=y, training_frame=h2o_df)\n",
        "        model = aml.leader\n",
        "        model_metrics = model.model_performance()._metric_json\n",
        "        # compare the metrics of the leader with the threshold, if they are less than the threshold, we include deeplearning\n",
        "        include_dl = False\n",
        "        if prob_type == \"classification\": #if classification we compare the logloss to the threshold\n",
        "            if float(model_metrics['logloss']) > 0.2:\n",
        "                include_dl = True\n",
        "        elif float(model_metrics['r2']) < 0.8: #if regression we compare the r2 to the threshold\n",
        "            include_dl = True\n",
        "\n",
        "        if include_dl: # if the metrics of the model are not satisfying (we included deeplearning)\n",
        "            metric = model_metrics['logloss'] if prob_type == \"classification\" else model_metrics['r2']\n",
        "            # train another h2o model with including only deeplearning as algo and a maximum of 3 models (to miniize train time)\n",
        "            aml2 = H2OAutoML(max_models=2, seed=1, include_algos=[\"DeepLearning\"])\n",
        "            aml2.train(x=x, y=y, training_frame=h2o_df)\n",
        "            model2 = aml2.leader\n",
        "            # we compare the metrics of the two leaders we got and we take the leader with the best metrics\n",
        "            if prob_type == \"classification\":\n",
        "                if float(model2.model_performance()._metric_json['logloss']) < float(model_metrics['logloss']):\n",
        "                    model = model2\n",
        "            elif float(model2.model_performance()._metric_json['r2']) > float(model_metrics['r2']):\n",
        "                model = model2\n",
        "        # save the best model and extract its metrics in a json object\n",
        "        model_path = h2o.save_model(model=model, path=\"./models\", force=True)\n",
        "        model_metrics = model.model_performance()._metric_json\n",
        "\n",
        "        #if the problem is classification, we extract the metrics : auc, logloss and mse\n",
        "        if prob_type == \"classification\":\n",
        "            model_details = {\n",
        "                'model_id': model.model_id,\n",
        "                'model_type': model.algo,\n",
        "                'model_path': model_path,\n",
        "                'model_category': model_metrics['model_category'],\n",
        "                'AUC': model_metrics['AUC'],\n",
        "                'logloss': model_metrics['logloss'],\n",
        "                'MSE': model_metrics['MSE'],\n",
        "            }\n",
        "        else: #if the problem is classification, we extract the metrics : mse, rmse and r2\n",
        "            model_details = {\n",
        "                'model_id': model.model_id,\n",
        "                'model_type': model.algo,\n",
        "                'model_path': model_path,\n",
        "                'model_category': model_metrics['model_category'],\n",
        "                'MSE': model_metrics['MSE'],\n",
        "                'RMSE': model_metrics['RMSE'],\n",
        "                'R2': model_metrics['r2']\n",
        "            }\n",
        "\n",
        "        # change the task's status to done and add it's metrics and file path in the tasks queue\n",
        "        tasks[task_id]['status'] = TaskStatus.DONE\n",
        "        tasks[task_id]['model_details'] = model_details\n",
        "    except Exception as e:\n",
        "        tasks[task_id]['status'] = TaskStatus.ERROR\n",
        "        tasks[task_id]['error'] = str(e)\n",
        "\n",
        "@app.post('/train')\n",
        "async def train_model(file: UploadFile = File(...)):\n",
        "    # generate a random id for the task and add it to the queue withe status waiting\n",
        "    task_id = str(uuid.uuid4())\n",
        "    tasks[task_id] = {'status': TaskStatus.WAITING}\n",
        "    file_content = await file.read()\n",
        "    # schedule the task to be executed immediately (0) with priority 1, so all tasks will be executed with FIFO\n",
        "    scheduler.enter(0, 1, train_model_task, (task_id, file_content))\n",
        "    asyncio.create_task(run_scheduler())\n",
        "    #return the task's id\n",
        "    return JSONResponse(content={'task_id': task_id})\n",
        "\n",
        "@app.get('/monitor/{task_id}') #returns the json object containing the task's info\n",
        "async def monitor_task(task_id: str):\n",
        "    task = tasks.get(task_id)\n",
        "    if not task:\n",
        "        return JSONResponse(status_code=404, content={'error': 'Task not found'})\n",
        "    return JSONResponse(content=task)\n",
        "\n",
        "@app.post('/predict')\n",
        "async def predict_model(task_id: str = Form(...), file: UploadFile = File(...)):\n",
        "    #fetch task details based on the task_id\n",
        "    task_details = tasks.get(task_id)\n",
        "    if task_details is None:\n",
        "        return JSONResponse(status_code=404, content={'error': 'Task not found'})\n",
        "    #check if the task is still in progress\n",
        "    if task_details['status'] != \"done\":\n",
        "        return JSONResponse(content={\"message\": \"Task is still in progress\"})\n",
        "    model_details = task_details.get('model_details')\n",
        "    if model_details is None or model_details.get('model_path') is None:\n",
        "        return JSONResponse(status_code=404, content={'error': 'Model path not found'})\n",
        "\n",
        "    modelpath = model_details['model_path']\n",
        "    csv_data = StringIO((await file.read()).decode('utf-8'))\n",
        "    input_df = pd.read_csv(csv_data)\n",
        "    h2o_input_df = h2o.H2OFrame(input_df)\n",
        "    #load the saved h2o model\n",
        "    model = h2o.load_model(modelpath)\n",
        "    #make the prediction and convert it to a dataframe then dictionaries list (because the list is json serializable)\n",
        "    predictions = model.predict(h2o_input_df)\n",
        "    predictions_df = predictions.as_data_frame()\n",
        "    return JSONResponse(content=predictions_df.to_dict(orient=\"records\"))\n",
        "\n",
        "async def run_scheduler():\n",
        "    loop = asyncio.get_event_loop()\n",
        "    await loop.run_in_executor(None, scheduler.run)\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    loop = asyncio.get_running_loop()\n",
        "    loop.create_task(run_scheduler())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWo64w0k0Cd2",
        "outputId": "6ada9143-3d08-48d8-fb44-2d724802426c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://20af-34-83-164-103.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (0.0.9)\n",
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content']\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m3627\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n",
            "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
            "--------------------------  -----------------------------------------------------------------------------------------\n",
            "H2O_cluster_uptime:         10 mins 40 secs\n",
            "H2O_cluster_timezone:       Etc/UTC\n",
            "H2O_data_parsing_timezone:  UTC\n",
            "H2O_cluster_version:        3.46.0.4\n",
            "H2O_cluster_version_age:    1 month and 6 days\n",
            "H2O_cluster_name:           H2O_from_python_unknownUser_p5tqe7\n",
            "H2O_cluster_total_nodes:    1\n",
            "H2O_cluster_free_memory:    3.167 Gb\n",
            "H2O_cluster_total_cores:    2\n",
            "H2O_cluster_allowed_cores:  2\n",
            "H2O_cluster_status:         locked, healthy\n",
            "H2O_connection_url:         http://localhost:54321\n",
            "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
            "H2O_internal_security:      False\n",
            "Python_version:             3.10.12 final\n",
            "--------------------------  -----------------------------------------------------------------------------------------\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m3633\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mPOST /train HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            ")| 100%\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mGET /monitor/a0ecb4bc-1961-4413-bba6-73e6d969cc61 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            ")| 100%\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mGET /monitor/a0ecb4bc-1961-4413-bba6-73e6d969cc61 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" \u001b[31m422 Unprocessable Entity\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" \u001b[31m422 Unprocessable Entity\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" \u001b[31m422 Unprocessable Entity\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" \u001b[31m422 Unprocessable Entity\u001b[0m\n",
            "Parse progress: |███████████████ (done)| 100%\n",
            ")| 100%\n",
            "/usr/local/lib/python3.10/dist-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
            "\u001b[32mINFO\u001b[0m:     102.159.100.20:0 - \"\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-08-16T17:25:54+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-79d5f30c-5e6c-4437-83de-0c34ad2474f0 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m3633\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m3627\u001b[0m]\n"
          ]
        }
      ],
      "source": [
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "!pip install python-multipart\n",
        "!uvicorn app:app --host 0.0.0.0 --port 8000 --reload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdKpfFHs0ImU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
